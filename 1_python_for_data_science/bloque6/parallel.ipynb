{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Going parallel with IPython: the basics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preliminaries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "IPython parallel was an integral part of IPython time ago, but now it is a separate package. Install instructions here:\n",
    "https://ipyparallel.readthedocs.io/en/latest/index.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checking execution in a cluster"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are dealing here with clusters of IPython engines **in your same computer**. \n",
    "\n",
    "You can start clusters from the IPython clusters tab, if you installed the Notebook server extension:\n",
    "\n",
    "$ ipcluster nbextension enable \n",
    "\n",
    "Alternatively, there is a command line interface to start clusters, for example:\n",
    "\n",
    "$ ipcluster start -n 4\n",
    "\n",
    "If you execute the following code, you will see the ids of the four engines you have started up."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1, 2, 3]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "|import ipyparallel as ipp\n",
    "rc = ipp.Client()\n",
    "rc.ids"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now for a simple execution on the cluster we are going to use the following function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def longrun(n):\n",
    "    from random import randint\n",
    "    bignumber = 0\n",
    "    for i in range(n):\n",
    "       bignumber += randint(1,100)\n",
    "    return bignumber"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 loops, best of 3: 152 ms per loop\n"
     ]
    }
   ],
   "source": [
    "%timeit longrun(100000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code has been executed in the **default kernel**, we can see its process id with the following."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14577\n"
     ]
    }
   ],
   "source": [
    "from os import getpid\n",
    "print(getpid())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now it is time to use the cluster for executing the function. We have to use apply_sync to execute it synchronously."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The slowest run took 4.33 times longer than the fastest. This could mean that an intermediate result is being cached.\n",
      "1 loop, best of 3: 151 ms per loop\n"
     ]
    }
   ],
   "source": [
    "%timeit rc[2].apply_sync(longrun, 100000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14552"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rc[0].apply_sync(getpid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can do parallel execution simply by referring to a view of nodes, i.e. a list of engines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[14552, 14557, 14558, 14559]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rc[:].apply_sync(getpid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 loop, best of 3: 308 ms per loop\n"
     ]
    }
   ],
   "source": [
    "%timeit ns = rc[:].apply_sync(longrun, 100000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "<class 'ipyparallel.client.view.DirectView'>\n"
     ]
    }
   ],
   "source": [
    "print(len(rc[1:3]))\n",
    "print(type(rc[:]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note the function has been executed as many times as engines in the view."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[508856, 501081, 508670, 503339]\n"
     ]
    }
   ],
   "source": [
    "ns = rc[:].apply_sync(longrun, 10000)\n",
    "print(ns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is called the <b>direct view</b> that basically works as a multiplexer, i.e. it broadcast the computation (the function in this case) to all the nodes specified."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mapping computations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use the <a href=\"https://docs.python.org/2/library/functions.html#map\">map built-in</a> to spread execution among engines. The following example calls longrun four times, one per each of the elements in the list passed, using **regular non-parallel Python**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the map applies the computation to **each element** in the list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[48435, 25688, 50247, 9824]\n"
     ]
    }
   ],
   "source": [
    "# This is the regular map built-in in Python:\n",
    "r = map(longrun, [1000, 500, 1000, 200])\n",
    "print(list(r))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Views have a **map** method that works similarly to the map built-in but does parallel execution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[49961, 24407, 48716, 10029, 20708, 41518]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "view = rc.load_balanced_view()\n",
    "view.map_sync(longrun, [1000, 500, 1000, 200, 400, 800])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that times are in general worse than using non-parallel Python, but this is just because we are using a local in-process cluster, and the overhead of the communication to engines adds time for a relatively short computation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ipyparallel.client.view.LoadBalancedView"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(view)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is using the controller to load balance so leaving decisions to the underlying infrastructure."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The map is different from **parallel functions**. Parallel functions split the computation in as many tasks as engines, not as elements in the list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "v = rc[:]\n",
    "@v.parallel(block=True, )\n",
    "def longrunparallel(x):\n",
    "    return(len(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "102\n",
      "[26, 26, 25, 25] 102\n"
     ]
    }
   ],
   "source": [
    "ret = longrunparallel(range(102))\n",
    "print (len(range(102)))\n",
    "print(ret, sum(ret))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Details on running parallel functions are here:\n",
    "http://ipython.org/ipython-doc/rel-0.11/api/generated/IPython.parallel.client.remotefunction.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Engines are dicts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using dict syntax with views works as push/pull operations of variables in particular processes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rc[1][\"myVarIn1\"] = \"I am in 1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'myVarIn1' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-42-e4514dc7b59c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mmyVarIn1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'myVarIn1' is not defined"
     ]
    }
   ],
   "source": [
    "print (myVarIn1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I am in 1\n"
     ]
    },
    {
     "ename": "RemoteError",
     "evalue": "NameError(name 'myVarIn1' is not defined)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m\u001b[0;31mNameError\u001b[0mTraceback (most recent call last)\u001b[0;32m<string>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m",
      "\u001b[0;32m/Users/msicilia/anaconda3/lib/python3.5/site-packages/ipyparallel/util.py\u001b[0m in \u001b[0;36m_pull\u001b[0;34m(keys)\u001b[0m",
      "\u001b[1;32m    257\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mglobals\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mkeys\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m",
      "\u001b[1;32m    258\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m",
      "\u001b[0;32m--> 259\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mglobals\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m",
      "\u001b[0m\u001b[1;32m    260\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m",
      "\u001b[1;32m    261\u001b[0m \u001b[0;34m@\u001b[0m\u001b[0minteractive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m",
      "\u001b[0;32m<string>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'myVarIn1' is not defined"
     ]
    }
   ],
   "source": [
    "print(rc[1][\"myVarIn1\"])\n",
    "print (rc[0][\"myVarIn1\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we use parallel.Reference(\"x\") in apply() functions, we are referring to a variable x that is already remote. This way, we can avoid copying the same variable through the network in several calls to apply. Think if x is a large array, this will save a lot of time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scatter and gather"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clusters start to become useful when you can partition data to do operations in pieces of data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "# The magic is needed to execute it in every instance \n",
    "# (you could alternatively place the import inside the function)\n",
    "\n",
    "%px import numpy as np \n",
    "def CostlyOperation():\n",
    "    global a  \n",
    "    array = np.copy(a)\n",
    "    return array*array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scatter/gather take an array and partition it among the parallel instances available."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.76282399 -0.36440919  1.59916077 ...,  2.70057731  0.11940081\n",
      "  2.68023101] 200000\n",
      "<DirectView [0, 1, 2, 3]>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([ 0.76282399, -0.36440919,  1.59916077, ...,  0.89453239,\n",
       "         0.70317073,  0.59536623]),\n",
       " array([-0.14962874,  2.17051201,  2.30378551, ..., -0.26951869,\n",
       "         1.89702123, -2.16316327]),\n",
       " array([-1.04528056, -0.42361677,  2.69030795, ...,  1.15064081,\n",
       "         0.29789342,  1.58629635]),\n",
       " array([ 0.10011466,  0.516968  ,  0.41366228, ...,  2.70057731,\n",
       "         0.11940081,  2.68023101])]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = np.random.randn(200000)+1\n",
    "print (a, len(a))\n",
    "other_view = rc[:]\n",
    "print (other_view)\n",
    "\n",
    "other_view.scatter('a', a)\n",
    "# With other_view['a'] you can see the partitions\n",
    "other_view['a']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 loops, best of 3: 11.8 ms per loop\n",
      "1000 loops, best of 3: 868 µs per loop\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([ 0.58190045,  0.13279406,  2.55731518, ...,  0.80018819,\n",
       "         0.49444908,  0.35446094]),\n",
       " array([ 0.02238876,  4.71112238,  5.30742768, ...,  0.07264033,\n",
       "         3.59868954,  4.67927535]),\n",
       " array([ 1.09261146,  0.17945117,  7.23775689, ...,  1.32397427,\n",
       "         0.08874049,  2.51633612]),\n",
       " array([ 0.01002295,  0.26725591,  0.17111648, ...,  7.29311782,\n",
       "         0.01425655,  7.18363827])]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# In this case, parallel execution is slower, as we are\n",
    "# doing it in the same machine, but with more data transfer.\n",
    "%timeit other_view.apply_sync(CostlyOperation)\n",
    "%timeit CostlyOperation()\n",
    "\n",
    "other_view.apply_sync(CostlyOperation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now you can recover values with gather:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.76282399 -0.36440919  1.59916077 ...,  2.70057731  0.11940081\n",
      "  2.68023101] 200000\n"
     ]
    }
   ],
   "source": [
    "other_view.block=True # Needed so that we wait for all the \n",
    "\n",
    "# We can get the original a that was distributed this way:\n",
    "b = other_view.gather(\"a\")\n",
    "print (b, len(b))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Working with multiple (Internet)data, same program"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In some cases, the same program needs to repeat a task from different parts of the data, and these data are external to our system. This is a good case for ad hoc parallel computation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For example, if we want to count n-gram data from Google:\n",
    "\n",
    "http://storage.googleapis.com/books/ngrams/books/datasetsv2.html\n",
    "\n",
    "We can distribute the list of files to the cluster, and each node will download a different piece of data from Google."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[422, 4810, 1951, 312798]\n"
     ]
    }
   ],
   "source": [
    "# Some files from Google, this could be a complete list generated usign loops.\n",
    "files = [\"googlebooks-eng-all-5gram-20120701-zk.gz\", \n",
    "         \"googlebooks-eng-all-5gram-20120701-zl.gz\", \n",
    "         \"googlebooks-eng-all-5gram-20120701-zm.gz\", \n",
    "         \"googlebooks-eng-all-5gram-20120701-zn.gz\", \n",
    "        ]\n",
    "\n",
    "%px import wget\n",
    "%px import gzip\n",
    "\n",
    "\n",
    "clus = rc[:]\n",
    "#manda trabajo asincrono\n",
    "@clus.parallel(block=False, )\n",
    "def countngrams(filename):\n",
    "    base_url = \"http://storage.googleapis.com/books/ngrams/books/\"\n",
    "    wget.download(base_url + filename[0])\n",
    "    lines = 0\n",
    "    with gzip.open(filename[0], 'r') as f:\n",
    "        for line in f:\n",
    "            lines+=1\n",
    "    return lines\n",
    "\n",
    "# This is the blocking sequential version:\n",
    "#for f in files:\n",
    "#import wget\n",
    "#import gzip\n",
    "#    res = countngrams(f)\n",
    "#    print(res)\n",
    "\n",
    "import time\n",
    "\n",
    "res = countngrams(files)\n",
    "#cuando el calculo termina imprime\n",
    "while not res.ready():\n",
    "    time.sleep(5)\n",
    "    \n",
    "print(res.result())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this case, the call was non-blocking, so that we get a handle to retrive the data later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Out-of-core con Dask.ipynb  log\r\n",
      "bloque6.zip                 mydask.png\r\n",
      "bloque6_guia.docx           myfile.hdf5\r\n",
      "bloque6_guia.pdf            \u001b[34mnoaa\u001b[m\u001b[m/\r\n",
      "datos_sensor.hdf5           parallel.ipynb\r\n",
      "ipython-parallel.PPT\r\n"
     ]
    }
   ],
   "source": [
    "%ls\n",
    "#%rm *.gz\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
